{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, plot_roc_curve, accuracy_score\n",
    "\n",
    "pd.set_option('display.max_columns', None) \n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import clone\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import XyScaler\n",
    "from roc_curve2 import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event1 = pd.read_csv('/home/allen/Galva/capstones/capstone2/data/Train/First_Health_Camp_Attended.csv')\n",
    "event2 = pd.read_csv('/home/allen/Galva/capstones/capstone2/data/Train/Second_Health_Camp_Attended.csv')\n",
    "event3 = pd.read_csv('/home/allen/Galva/capstones/capstone2/data/Train/Third_Health_Camp_Attended.csv')\n",
    "patient_df = pd.read_csv('/home/allen/Galva/capstones/capstone2/data/D7.csv')\n",
    "patient_df1 = patient_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_df1['Patient_ID'].unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X3a.to_csv('/home/allen/Galva/capstones/capstone2/data/D7.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "plt.rcParams['figure.dpi'] = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checker = pd.read_csv('/home/allen/Galva/capstones/capstone2/data/Patient_and_Target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = patient_df1['Event1_or_2'].values\n",
    "v1_count1 = [x for x in v1 if x==1]\n",
    "v1_count0 = [1 for x in v1 if x==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v11 = sum(v1_count1)\n",
    "v10 = sum(v1_count0)\n",
    "print(v10,v11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N = 1\n",
    "yes = (11068)\n",
    "no = (26565)\n",
    "ind = 1    # the x locations for the groups\n",
    "width = 0.35       # the width of the bars: can also be len(x) sequence\n",
    "\n",
    "p1 = plt.bar(ind, no, width)\n",
    "p2 = plt.bar(ind, yes, width,\n",
    "             bottom=no)\n",
    "\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Total Attendance')\n",
    "\n",
    "plt.yticks(np.arange(0, 45000 , 7500))\n",
    "plt.legend(('No', 'Yes'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edu = patient_df1['Education_Score2'].values\n",
    "edu_ = []\n",
    "for i in edu:\n",
    "    if i >=90 :\n",
    "        edu_.append(2)\n",
    "    elif i >=80 and i<90:\n",
    "        edu_.append(1)\n",
    "    else:\n",
    "        edu_.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(edu_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = patient_df1['Education_Scorez'].values\n",
    "t2 = np.array(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_df1['Edu1'] = patient_df1['Education_Scorez'].apply(lambda x:1 if x == 1 else 0)\n",
    "patient_df1['Edu2'] = patient_df1['Education_Scorez'].apply(lambda x:1 if x == 2 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/home/allen/Galva/capstones/capstone2/data/Train/Train.csv')\n",
    "train1 = train.copy()\n",
    "test_df = pd.read_csv('/home/allen/Galva/capstones/capstone2/data/test.csv') \n",
    "test_df1 = test_df.copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler =  StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1_1 = train1['Var1'].to_frame()\n",
    "train1_2 = train1['Var2'].to_frame()\n",
    "train1_3 = train1['Var3'].to_frame() \n",
    "train1_4 = train1['Var4'].to_frame() \n",
    "train1_5 = train1['Var5'].to_frame() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1_1 = scaler.fit_transform(train1_1 )\n",
    "train1_2 = scaler.fit_transform(train1_2 )\n",
    "train1_3 = scaler.fit_transform(train1_3 )\n",
    "train1_4 = scaler.fit_transform(train1_4 )\n",
    "train1_5 = scaler.fit_transform(train1_5 )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1['train1_1'] = train1_1\n",
    "train1['train1_2'] = train1_2\n",
    "train1['train1_3'] = train1_3\n",
    "train1['train1_4'] = train1_4\n",
    "train1['train1_5'] = train1_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1.drop(['Var1','Var2','Var3','Var4','Var5']  , axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1df1 = test_df1['Var1'].to_frame()\n",
    "test1df2 = test_df1['Var2'].to_frame()\n",
    "test1df3 = test_df1['Var3'].to_frame()\n",
    "test1df4 = test_df1['Var4'].to_frame()\n",
    "test1df5 = test_df1['Var5'].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1df1 = scaler.fit_transform(test1df1 )\n",
    "test1df2 = scaler.fit_transform(test1df2 )\n",
    "test1df3 = scaler.fit_transform(test1df3 )\n",
    "test1df4 = scaler.fit_transform(test1df4 )\n",
    "test1df5 = scaler.fit_transform(test1df5 )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df1['test1df1'] = test1df1\n",
    "test_df1['test1df2'] = test1df2\n",
    "test_df1['test1df3'] = test1df3\n",
    "test_df1['test1df4'] = test1df4\n",
    "test_df1['test1df5'] = test1df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df1.drop(['Var1','Var2','Var3','Var4','Var5']  , axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train1.to_csv('/home/allen/Galva/capstones/capstone2/data/train_scaled.csv')\n",
    "# test_df1.to_csv('/home/allen/Galva/capstones/capstone2/data/test_scaled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "print(df_head.to_markdown()) \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#patient_df1.to_csv('d5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X3a.to_csv('/home/allen/Galva/capstones/capstone2/data/D7.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import argmax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.columns)\n",
    "print(test_df.columns)\n",
    "print(patient_df1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = train1.merge(patient_df1, on=['Patient_ID'], how = 'left')\n",
    "test_df1 = test_df1.merge(patient_df1, on = ['Patient_ID'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train1.to_csv('/home/allen/Galva/capstones/capstone2/data/train_1.csv')\n",
    "# test_df1.to_csv('/home/allen/Galva/capstones/capstone2/data/test_df1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #.drop(['Patient_ID', 'Health_Camp_ID', 'Registration_Date', 'test1df1',\n",
    "#        'test1df2', 'test1df3', 'test1df4', 'test1df5', 'Unnamed: 0',\n",
    "#        'Unnamed: 0.1', 'Unnamed: 0.1.1', 'Online_Follower', 'LinkedIn_Shared',\n",
    "#        'Twitter_Shared', 'Facebook_Shared', 'Income', 'Education_Score', 'Age',\n",
    "#        'First_Interaction', 'City_Type', 'Employer_Category', 'Job_Type',\n",
    "#        'Event1_or_2', 'Education_Score2', 'Education_Scorez', '2', '3', '4',\n",
    "#        '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '9999', 'B', 'C',\n",
    "#        'D', 'E', 'F', 'G', 'H', 'I', 'Z', 'Edu1', 'Edu2'],axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.drop(['Patient_ID', 'Health_Camp_ID', 'Registration_Date', 'test1df1',\n",
    "#        'test1df2', 'test1df3', 'test1df4', 'test1df5', 'Unnamed: 0',\n",
    "#        'Unnamed: 0.1', 'Unnamed: 0.1.1', 'Online_Follower', 'LinkedIn_Shared',\n",
    "#        'Twitter_Shared', 'Facebook_Shared', 'Income', 'Education_Score', 'Age',\n",
    "#        'First_Interaction', 'City_Type', 'Employer_Category', 'Job_Type',\n",
    "#        'Event1_or_2', 'Education_Score2', 'Education_Scorez', '2', '3', '4',\n",
    "#        '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '9999', 'B', 'C',\n",
    "#        'D', 'E', 'F', 'G', 'H', 'I', 'Z', 'Edu1', 'Edu2'],axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'2', '3', '4', '5', '6', '7', '8','9', '10', '11', '12', '13', '14',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Unnamed: 0.1.1','Unnamed: 0', 'Unnamed: 0.1',\n",
    "# 'Registration_Date', 'Employer_Category','Patient_ID','First_Interaction', \n",
    "# 'Health_Camp_ID','Twitter_Shared','Facebook_Shared','Income','Education_Score',\n",
    "# 'Age', 'City_Type', 'Job_Type', \n",
    "# 'Education_Score2','Education_Scorez','5','12', '7', '2'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = train1.drop(['Unnamed: 0.1.1','Unnamed: 0', 'Unnamed: 0.1','Registration_Date', 'Employer_Category','Patient_ID','First_Interaction', 'Health_Camp_ID','Twitter_Shared','Facebook_Shared','Income','Education_Score','Age', 'City_Type', 'Job_Type', 'Education_Score2','Education_Scorez','2', '3', '4', '5', '6', '7', '8','9', '10', '11', '12', '14','B', 'C','D', 'E', 'F', 'G', 'H', 'I', 'Z', 'Edu1','Edu2'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df1 = test_df1.drop(['Unnamed: 0.1.1','Unnamed: 0', 'Unnamed: 0.1','Registration_Date', 'Employer_Category','Patient_ID','First_Interaction','Health_Camp_ID','Twitter_Shared','Facebook_Shared','Income','Education_Score','Age', 'City_Type', 'Job_Type', 'Education_Score2','Education_Scorez','2', '3', '4', '5', '6', '7', '8','9', '10', '11', '12', '14','B', 'C','D', 'E', 'F', 'G', 'H', 'I', 'Z', 'Edu1','Edu2'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1, y2 = train1.pop('Event1_or_2') , test_df1.pop('Event1_or_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 26,565"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test = train1 , test_df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logmodel = LogisticRegression(solver=\"lbfgs\")\n",
    "logmodel.fit(X_train, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logmodel.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_proba = logmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(pure_proba ))\n",
    "print(sum(y2) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, preds2 = predictions>.5 ,predictions>.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, coef in zip(preds2[1:], logmodel.coef_[0]):\n",
    "    print(\"{0}: {1:0.4f}\".format(name, coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y2,preds2) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y2,preds)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  8954  9552 ,\n",
    "#     3998 12745]]\n",
    "# # 26,565"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y2,preds) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y2,preds2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y2,preds2) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''[[ 9249  9257]\n",
    " [ 4080 12663]]\n",
    " FORESt\n",
    " '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tools import add_constant\n",
    "from statsmodels.discrete.discrete_model import Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test_df1\n",
    "X_const = add_constant(X, prepend=True)\n",
    "y3 = y2.copy()\n",
    "logit_model = Logit(y3, X_const).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5)\n",
    "\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "for train_index, test_index in kfold.split(X_train):\n",
    "    model = LogisticRegression(solver=\"lbfgs\")\n",
    "    model.fit(X_train.iloc[train_index], y1.iloc[train_index])\n",
    "    y_predict = model.predict(X_train.iloc[test_index])\n",
    "    y_true = y1.iloc[test_index]\n",
    "    accuracies.append(accuracy_score(y_true, y_predict))\n",
    "    precisions.append(precision_score(y_true, y_predict))\n",
    "    recalls.append(recall_score(y_true, y_predict))\n",
    "\n",
    "print(\"Accuracy:\", np.average(accuracies))\n",
    "print(\"Precision:\", np.average(precisions))\n",
    "print(\"Recall:\", np.average(recalls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "n=20 \n",
    "Accuracy: 0.6178722087906098\n",
    "Precision: 0.6242284105951045\n",
    "Recall: 0.9587480176361393\n",
    "'''\n",
    "#[[16088  2418]\n",
    " #[ 9349  7394]]\n",
    "'''\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.63      0.87      0.73     18506\n",
    "           1       0.75      0.44      0.56     16743\n",
    "\n",
    "    accuracy                           0.67     35249\n",
    "   macro avg       0.69      0.66      0.64     35249\n",
    "weighted avg       0.69      0.67      0.65     35249\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "1am night before\n",
    "Accuracy: 0.6787640530222973\n",
    "Precision: 0.7425212530267482\n",
    "Recall: 0.7106330368299469\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_plot(ax, x, y, x_label, y_label, title):\n",
    "    ax.plot(x, y)\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model3 = LogisticRegression(solver='lbfgs')\n",
    "model3.fit(X_train, y1)\n",
    "probabilities2 = model3.predict_proba(X_test)[:, 1]\n",
    "tpr, fpr, thresholds = roc_curve(probabilities2, y2)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "simple_plot(ax, fpr, tpr, \n",
    "            \"False Positive Rate (1 - Specificity)\", \n",
    "            \"True Positive Rate (Sensitivity, Recall)\", \n",
    "            \"ROC Plot of Patient Predictions Mod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.63      0.87      0.73     18506\n",
    "           1       0.75      0.44      0.56     16743\n",
    "\n",
    "    accuracy                           0.67     35249\n",
    "   macro avg       0.69      0.66      0.64     35249\n",
    "weighted avg       0.69      0.67      0.65     35249\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.73      0.35      0.48     18506\n",
    "           1       0.54      0.85      0.67     16743\n",
    "\n",
    "    accuracy                           0.59     35249\n",
    "   macro avg       0.64      0.60      0.57     35249\n",
    "weighted avg       0.64      0.59      0.57     35249\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "\n",
    "eNDOM FOREST 1AM\n",
    "\n",
    "[[ 9228  9278]\n",
    " [ 4058 12685]]\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators = 200)\n",
    "rfc.fit(X_train,y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_preds = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y2,rfc_preds) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y2,rfc_preds)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = RandomForestClassifier(n_estimators = 200)\n",
    "model4.fit(X_train, y1)\n",
    "proba_Forest = model4.predict_proba(X_test)[:, 1]\n",
    "tpr, fpr, thresholds = roc_curve(proba_Forest, y2)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "simple_plot(ax, fpr, tpr, \n",
    "            \"False Positive Rate (1 - Specificity)\", \n",
    "            \"True Positive Rate (Sensitivity, Recall)\", \n",
    "            \"ROC Plot Patient Predictions Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train1\n",
    "y_train = y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df1\n",
    "y_test= y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha=6)\n",
    "ridge.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rss(y, y_hat):\n",
    "    return np.mean((y  - y_hat)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = ridge.predict(X_test)\n",
    "mse = rss(y_test,preds)\n",
    "print(\"MSE for Ridge(alpha=2.5): {:2.2f}\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv(X, y, base_estimator, n_folds, random_seed=154):\n",
    "    \"\"\"Estimate the in and out-of-sample error of a model using cross validation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    X: np.array\n",
    "      Matrix of predictors.\n",
    "      \n",
    "    y: np.array\n",
    "      Target array.\n",
    "      \n",
    "    base_estimator: sklearn model object.\n",
    "      The estimator to fit.  Must have fit and predict methods.\n",
    "      \n",
    "    n_folds: int\n",
    "      The number of folds in the cross validation.\n",
    "      \n",
    "    random_seed: int\n",
    "      A seed for the random number generator, for repeatability.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "      \n",
    "    train_cv_errors, test_cv_errors: tuple of arrays\n",
    "      The training and testing errors for each fold of cross validation.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=n_folds, random_state=random_seed)\n",
    "    test_cv_errors, train_cv_errors = np.empty(n_folds), np.empty(n_folds)\n",
    "    for idx, (train, test) in enumerate(kf.split(X_train)):\n",
    "        # Split into train and test\n",
    "        X_cv_train, y_cv_train = X[train], y[train]\n",
    "        X_cv_test, y_cv_test = X[test], y[test]\n",
    "        # Standardize data.\n",
    "        standardizer = XyScaler()\n",
    "        standardizer.fit(X_cv_train, y_cv_train)\n",
    "        X_cv_train_std, y_cv_train_std = standardizer.transform(X_cv_train, y_cv_train)\n",
    "        X_cv_test_std, y_cv_test_std = standardizer.transform(X_cv_test, y_cv_test)\n",
    "        # Fit estimator\n",
    "        estimator = clone(base_estimator)\n",
    "        estimator.fit(X_cv_train_std, y_cv_train_std)\n",
    "        # Measure performance\n",
    "        y_hat_train = estimator.predict(X_cv_train_std)\n",
    "        y_hat_test = estimator.predict(X_cv_test_std)\n",
    "        # Calclate the error metrics\n",
    "        train_cv_errors[idx] = rss(y_cv_train_std, y_hat_train)\n",
    "        test_cv_errors[idx] = rss(y_cv_test_std, y_hat_test)\n",
    "    return train_cv_errors, test_cv_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_folds = 10\n",
    "train_cv_errors, test_cv_errors = cv(X_train.values, y_train.values, \n",
    "                                     Ridge(alpha=6), n_folds=n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training CV error: {:2.2f}\".format(train_cv_errors.mean()))\n",
    "print(\"Test CV error: {:2.2f}\".format(test_cv_errors.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_at_various_alphas(X, y, model, alphas, n_folds=10, **kwargs):\n",
    "    \"\"\"Train a regularized regression model using cross validation at various values of alpha.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    X: np.array\n",
    "      Matrix of predictors.\n",
    "      \n",
    "    y: np.array\n",
    "      Target array.\n",
    "      \n",
    "    model: sklearn model class\n",
    "      A class in sklearn that can be used to create a regularized regression object.  Options are `Ridge` and `Lasso`.\n",
    "      \n",
    "    alphas: numpy array\n",
    "      An array of regularization parameters.\n",
    "      \n",
    "    n_folds: int\n",
    "      Number of cross validation folds.\n",
    "      \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    cv_errors_train, cv_errors_test: tuple of DataFrame\n",
    "      DataFrames containing the training and testing errors for each value of \n",
    "      alpha and each cross validation fold.  Each row represents a CV fold,\n",
    "      and each column a value of alpha.\n",
    "    \"\"\"\n",
    "    cv_errors_train = pd.DataFrame(np.empty(shape=(n_folds, len(alphas))),\n",
    "                                     columns=alphas)\n",
    "    cv_errors_test = pd.DataFrame(np.empty(shape=(n_folds, len(alphas))),\n",
    "                                        columns=alphas)\n",
    "    for alpha in alphas:\n",
    "        train_fold_errors, test_fold_errors = cv(X, y, model(alpha=alpha, **kwargs), n_folds=n_folds)\n",
    "        cv_errors_train.loc[:, alpha] = train_fold_errors\n",
    "        cv_errors_test.loc[:, alpha] = test_fold_errors\n",
    "    return cv_errors_train, cv_errors_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_alphas = np.logspace(-2, 4, num=250)\n",
    "\n",
    "ridge_cv_errors_train, ridge_cv_errors_test = train_at_various_alphas(\n",
    "    X_train.values, y_train.values, Ridge, ridge_alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_mean_cv_errors_train = ridge_cv_errors_train.mean(axis=0)\n",
    "ridge_mean_cv_errors_test = ridge_cv_errors_test.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_alpha(mean_cv_errors_test):\n",
    "    alphas = mean_cv_errors_test.index\n",
    "    optimal_idx = np.argmin(mean_cv_errors_test.values)\n",
    "    optimal_alpha = alphas[optimal_idx]\n",
    "    return optimal_alpha\n",
    "\n",
    "ridge_optimal_alpha = get_optimal_alpha(ridge_mean_cv_errors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 4))\n",
    "\n",
    "ax.plot(np.log10(ridge_alphas), ridge_mean_cv_errors_train)\n",
    "ax.plot(np.log10(ridge_alphas), ridge_mean_cv_errors_test)\n",
    "ax.axvline(np.log10(ridge_optimal_alpha), color='grey')\n",
    "ax.set_title(\"Ridge Regression Train and Test MSE\")\n",
    "ax.set_xlabel(r\"$\\log(\\alpha)$\")\n",
    "ax.set_ylabel(\"MSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_models = []\n",
    "\n",
    "for alpha in ridge_alphas:\n",
    "    scaler = XyScaler()\n",
    "    scaler.fit(X_train.values, y_train.values)\n",
    "    X_train_std, y_train_std = scaler.transform(X_train.values, y_train.values)\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    ridge.fit(X_train_std, y_train_std)\n",
    "    ridge_models.append(ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = pd.DataFrame(np.empty(shape=(len(ridge_alphas), len(X_train.columns))),\n",
    "                     index=ridge_alphas, columns=X_train.columns)\n",
    "\n",
    "for idx, model in enumerate(ridge_models):\n",
    "    paths.iloc[idx] = model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 4))\n",
    "\n",
    "for column in X_train.columns:\n",
    "    path = paths.loc[:, column]\n",
    "    ax.plot(np.log10(ridge_alphas), path, label=column)\n",
    "ax.axvline(np.log10(ridge_optimal_alpha), color='grey')\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_title(\"Ridge Regression, Standardized Coefficient Paths\")\n",
    "ax.set_xlabel(r\"$\\log(\\alpha)$\")\n",
    "ax.set_ylabel(\"Standardized Coefficient\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
