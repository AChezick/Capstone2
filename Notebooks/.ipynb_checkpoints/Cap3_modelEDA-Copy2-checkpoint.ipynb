{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "#import seaborn as sns \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, plot_roc_curve, accuracy_score\n",
    "\n",
    "pd.set_option('display.max_columns', None) \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import clone\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import XyScaler\n",
    "from roc_curve2 import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "checker = pd.read_csv('/home/allen/Galva/capstones/capstone2/src/explore/train_4_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_withID = pd.read_csv('/home/allen/Galva/capstones/capstone2/src/explore/ready12_24_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checker['patient_event'] = df_withID['patient_event']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>y_target</th>\n",
       "      <th>delta_first_reg</th>\n",
       "      <th>interaction_regreister_delta</th>\n",
       "      <th>delta_first_start</th>\n",
       "      <th>delta_reg_end</th>\n",
       "      <th>Camp_Length</th>\n",
       "      <th>Second</th>\n",
       "      <th>Third</th>\n",
       "      <th>1036</th>\n",
       "      <th>1216</th>\n",
       "      <th>1217</th>\n",
       "      <th>1352</th>\n",
       "      <th>1704</th>\n",
       "      <th>1729</th>\n",
       "      <th>2517</th>\n",
       "      <th>2662</th>\n",
       "      <th>23384</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>2100</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>6.0</th>\n",
       "      <th>7.0</th>\n",
       "      <th>8.0</th>\n",
       "      <th>9.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>11.0</th>\n",
       "      <th>12.0</th>\n",
       "      <th>13.0</th>\n",
       "      <th>14.0</th>\n",
       "      <th>9999.0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.420086</td>\n",
       "      <td>-0.063285</td>\n",
       "      <td>-0.019631</td>\n",
       "      <td>-0.11236</td>\n",
       "      <td>1.442928</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.059341</td>\n",
       "      <td>0.257361</td>\n",
       "      <td>0.392104</td>\n",
       "      <td>-0.394391</td>\n",
       "      <td>-0.529413</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.104391</td>\n",
       "      <td>-0.063285</td>\n",
       "      <td>-0.019631</td>\n",
       "      <td>-0.11236</td>\n",
       "      <td>-0.204613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062659</td>\n",
       "      <td>-0.205094</td>\n",
       "      <td>-0.201865</td>\n",
       "      <td>-0.015115</td>\n",
       "      <td>-0.084562</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.420086</td>\n",
       "      <td>-0.063285</td>\n",
       "      <td>-0.019631</td>\n",
       "      <td>-0.11236</td>\n",
       "      <td>1.442928</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.056754</td>\n",
       "      <td>0.456294</td>\n",
       "      <td>0.532254</td>\n",
       "      <td>1.627418</td>\n",
       "      <td>1.984351</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Var1      Var2      Var3     Var4      Var5  y_target  delta_first_reg  \\\n",
       "0  0.420086 -0.063285 -0.019631 -0.11236  1.442928       1.0         0.059341   \n",
       "1 -0.104391 -0.063285 -0.019631 -0.11236 -0.204613       0.0         0.062659   \n",
       "2  0.420086 -0.063285 -0.019631 -0.11236  1.442928       0.0        -0.056754   \n",
       "\n",
       "   interaction_regreister_delta  delta_first_start  delta_reg_end  \\\n",
       "0                      0.257361           0.392104      -0.394391   \n",
       "1                     -0.205094          -0.201865      -0.015115   \n",
       "2                      0.456294           0.532254       1.627418   \n",
       "\n",
       "   Camp_Length  Second  Third  1036  1216  1217  1352  1704  1729  2517  2662  \\\n",
       "0    -0.529413       0      1     0     0     0     0     0     0     0     0   \n",
       "1    -0.084562       0      0     0     0     0     0     0     0     0     0   \n",
       "2     1.984351       0      0     0     0     0     0     0     0     0     0   \n",
       "\n",
       "   23384  B  C  D  E  F  G  2100  2.0  3.0  4.0  5.0  6.0  7.0  8.0  9.0  \\\n",
       "0      1  0  0  0  0  0  1     1    0    0    0    0    0    0    0    0   \n",
       "1      1  0  0  0  0  1  0     1    0    0    0    0    0    0    0    0   \n",
       "2      1  0  0  0  0  1  0     1    0    0    0    0    0    0    0    0   \n",
       "\n",
       "   10.0  11.0  12.0  13.0  14.0  9999.0  1  2  3  4  \n",
       "0     0     0     0     0     0       1  0  0  0  0  \n",
       "1     0     0     0     0     0       1  0  0  0  0  \n",
       "2     0     0     0     0     0       1  0  0  0  0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checker.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "checker[\"Camp Start Date - Registration Date\"] = checker['delta_first_reg']\n",
    "checker[ \"Registration Date - First Interaction\"] = checker['interaction_regreister_delta']\n",
    "checker[\"Camp Start Date - First Ineraction\"]=checker['delta_first_start']\n",
    "checker[\"Camp End Date - Registration Date\"]=checker['delta_reg_end']\n",
    "checker['Camp Length'] = checker['Camp_Length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "too_drop=['delta_first_reg',\n",
    "       'interaction_regreister_delta', 'delta_first_start', 'delta_reg_end',\n",
    "       'Camp_Length']\n",
    "checker = checker.drop(too_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import argmax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n 6   delta_first_reg               75278 non-null  float64\\n 7   interaction_regreister_delta  75278 non-null  float64\\n 8   delta_first_start             75278 non-null  float64\\n 9   delta_reg_end                 75278 non-null  float64\\n\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "'''\n",
    " 6   delta_first_reg               75278 non-null  float64\n",
    " 7   interaction_regreister_delta  75278 non-null  float64\n",
    " 8   delta_first_start             75278 non-null  float64\n",
    " 9   delta_reg_end                 75278 non-null  float64\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'delta_first_reg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'delta_first_reg'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-dee71af6cdc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# make hist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mchecker\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchecker\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'delta_first_reg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mchecker\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchecker\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'delta_first_reg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2902\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2903\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'delta_first_reg'"
     ]
    }
   ],
   "source": [
    "# make hist \n",
    "checker[checker['y_target'] ==1][\"Camp Start Date - Registration Date\"].hist(alpha=.6)\n",
    "checker[checker['y_target'] ==0][\"Camp Start Date - Registration Date\"].hist(alpha=.6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checker2 = checker.copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_check = checker.dropna(axis=1)\n",
    "#print(some_check.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_ratio = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkerxx = checker.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checker.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checker = checker.copy()\n",
    "# checker = checker.drop(['Var4','11.0', '12.0', '13.0', '14.0','1217', '1352',\n",
    "#        '1704', '1729', '2517', '2662','7.0','4.0','6.0','3.0'],axis=1)\n",
    "checker1 = checker.copy() \n",
    "\n",
    "checker3 = checker.copy() \n",
    "checker4 = checker.copy() \n",
    "checker5 = checker.copy() \n",
    "checker7 = checker.copy()  \n",
    "checker8 = checker.copy() \n",
    "checker9 = checker.copy() \n",
    "checker10 = checker.copy() \n",
    "checker11 = checker.copy()  \n",
    "\n",
    "checker_base = checker.copy() \n",
    "trump= [ 'delta_first_reg',\n",
    "       'interaction_regreister_delta', 'delta_first_start', 'delta_reg_end',\n",
    "       'Camp_Length', 'Second', 'Third', '1036', '1216', '23384', 'B', 'C',\n",
    "       'D', 'E', 'F', 'G', '2100', '2.0', '5.0', '8.0', '9.0', '10.0',\n",
    "       '9999.0', '1', '2', '3', '4']\n",
    "checker_base   = checker.drop(trump, axis=1)\n",
    "cb1 = checker_base.copy() \n",
    "cb2 = checker_base.copy()\n",
    "cb3 = checker_base.copy() \n",
    "cb4 = checker_base.copy() \n",
    "cb5 = checker_base.copy()  \n",
    "cb7 = checker_base.copy()  \n",
    "cb9 = checker_base.copy()  \n",
    "cb10 = checker_base.copy()  \n",
    "cb11 = checker_base.copy()  \n",
    "cb12 = checker_base.copy()  \n",
    "cb20 = checker_base.copy()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_to_test = checker11['y_target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ynotx = y_to_test \n",
    "train_test_split(ynotx, shuffle=False) \n",
    "X_train,X_test,y_train,y_test = train_test_split(\n",
    "    checker11,ynotx,test_size = .2, random_state=101)\n",
    "\n",
    "print(X_train, X_test, y_train,y_test)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logmodelx = LogisticRegression(penalty='l2', dual=False, tol=1e-4, C=1.0, \n",
    "        fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, \n",
    "        solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, \n",
    "        n_jobs=1, l1_ratio=None ) \n",
    "logmodelx.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_probx= logmodelx.predict_proba(X_test)[:,1]\n",
    "predx = logmodelx.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = [ X_train, X_test, y_train,y_test,predx,pure_probx]\n",
    "for i in g:\n",
    "    print(len(i))\n",
    "Xs = X_train - X_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "A. Take X_train - X_test that creates == TO_check <56458-18820> = 37639\n",
    "B. Add the column from [logmodelx.predict_proba(X_test)[:,1]] to Take TO_check\n",
    "\n",
    "def get_specifics(X_train, y_train,predx ):\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predsx, preds2x = predx >= .45 ,predx >= .55\n",
    "for name, coef in zip(predsx[1:], logmodelx.coef_[0]):\n",
    "    print(\"{0}: {1:0.4f}\".format(name, coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(predsx), len(X_train), len(X_test))\n",
    "X_train_len = len(X_train)\n",
    "X_test_len = len(X_test)\n",
    "print(X_train_len - X_test_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,preds2x) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,preds2x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,predsx) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_try = confusion_matrix(y_test,predsx)\n",
    "print(to_try) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(.7+ .36) / (.8 * .94)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checker1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ynot1 = checker1.pop('y_target')\n",
    " \n",
    "\n",
    "train_test_split(ynot1, shuffle=False) \n",
    "X_train,X_test,y_train,y_test = train_test_split(\n",
    "    checker1,ynot1,test_size = .2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logmodel = LogisticRegression(penalty='l2', dual=False, tol=1e-4, C=1.0, \n",
    "        fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, \n",
    "        solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, \n",
    "        n_jobs=-1, l1_ratio=None ) \n",
    "logmodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_probaz = logmodel.predict_proba(X_test)[:,1]\n",
    "predictionsz = logmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_probaz  \n",
    "#predictionsz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_logmodel = roc_auc_score(y_test, logmodel.fit(X_train, y_train).predict_proba(X_test)[:, -1]) \n",
    "print(roc_auc_logmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logmodel_disp = plot_roc_curve(logmodel, X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predsz, preds2z = pure_probaz >= .35 ,pure_probaz >= .5\n",
    "# for name, coef in zip(preds2z[1:], logmodel.coef_[0]):\n",
    "#     print(\"{0}: {1:0.4f}\".format(name, coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,preds2z) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,predsz) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,preds2z))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,predsz)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import partial_dependence\n",
    "from sklearn.inspection import plot_partial_dependence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Var3', 'Var4'] \n",
    "'''#, \n",
    ", 'delta_first_reg',\n",
    "       'interaction_regreister_delta', 'delta_first_start', 'delta_reg_end',\n",
    "       'Camp_Length', 'Second', 'Third', '1036', '1216', '1217', '1352',\n",
    "       '1704', '1729', '2517', '2662', '23384', 'B', 'C', 'D', 'E', 'F', 'G',\n",
    "       '2100', '2.0', '3.0', '4.0', '5.0', '6.0', '7.0', '8.0', '9.0', '10.0',\n",
    "       '11.0', '12.0', '13.0', '14.0', '9999.0', '1', '2', '3', '4'\n",
    "'''\n",
    "\n",
    "display = plot_partial_dependence(logmodel, X_train, features)\n",
    "\n",
    "display.figure_.suptitle( 'Partial dependence ' )\n",
    "display.figure_.subplots_adjust(hspace=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Var5' ] \n",
    "'''#, \n",
    ", 'delta_first_reg',\n",
    "       'interaction_regreister_delta', 'delta_first_start', 'delta_reg_end',\n",
    "       'Camp_Length', 'Second', 'Third', '1036', '1216', '1217', '1352',\n",
    "       '1704', '1729', '2517', '2662', '23384', 'B', 'C', 'D', 'E', 'F', 'G',\n",
    "       '2100', '2.0', '3.0', '4.0', '5.0', '6.0', '7.0', '8.0', '9.0', '10.0',\n",
    "       '11.0', '12.0', '13.0', '14.0', '9999.0', '1', '2', '3', '4'\n",
    "'''\n",
    "\n",
    "display = plot_partial_dependence(logmodel, X_train, features)\n",
    "\n",
    "display.figure_.suptitle( 'Partial dependence ' )\n",
    "display.figure_.subplots_adjust(hspace=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this will break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['delta_first_reg',\n",
    "       'interaction_regreister_delta'] \n",
    "'''#, 'Var3', 'Var4', 'Var5'\n",
    ", , 'delta_first_start', 'delta_reg_end',\n",
    "       'Camp_Length', 'Second', 'Third', '1036', '1216', '1217', '1352',\n",
    "       '1704', '1729', '2517', '2662', '23384', 'B', 'C', 'D', 'E', 'F', 'G',\n",
    "       '2100', '2.0', '3.0', '4.0', '5.0', '6.0', '7.0', '8.0', '9.0', '10.0',\n",
    "       '11.0', '12.0', '13.0', '14.0', '9999.0', '1', '2', '3', '4'\n",
    "'''\n",
    "\n",
    "display = plot_partial_dependence(logmodel, X_test, features)\n",
    "\n",
    "display.figure_.suptitle( 'Partial dependence ' )\n",
    "display.figure_.subplots_adjust(hspace=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = checker10.pop('y_target') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5)\n",
    "\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(checker10, y1)\n",
    "\n",
    "for train_index, test_index in kfold.split(X_train):\n",
    "    model = LogisticRegression(solver=\"lbfgs\")\n",
    "    model.fit(X_train.iloc[train_index], y1.iloc[train_index])\n",
    "    y_predict = model.predict(X_train.iloc[test_index])\n",
    "    y_true = y1.iloc[test_index]\n",
    "    accuracies.append(accuracy_score(y_true, y_predict))\n",
    "    precisions.append(precision_score(y_true, y_predict))\n",
    "    recalls.append(recall_score(y_true, y_predict))\n",
    "\n",
    "print(\"Accuracy:\", np.average(accuracies))\n",
    "print(\"Precision:\", np.average(precisions))\n",
    "print(\"Recall:\", np.average(recalls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#ynot1 = cb12.pop('y_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# y = checker8.pop('y_target')\n",
    "# X = checker8\n",
    "\n",
    "y = cb7.pop('y_target')\n",
    "X = cb7\n",
    "\n",
    "X_train7, X_test7, y_train7, y_test7 = train_test_split(X, y, random_state=42)\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators = 200, max_depth = 10)\n",
    "rfc.fit(X_train7,y_train7)\n",
    "rfc_preds = rfc.predict(X_test7)\n",
    "roc_auc=roc_auc_score(y_test7, rfc.predict_proba(X_test7)[:, -1])\n",
    "#roc_auc2 = roc_auc_score(y_test, rfc.decision_function(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,rfc_preds)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_partial_dependence(rfc, features=[5, 6, 7,8], feature_names=X_test7.columns, X=X_test7, grid_resolution=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_partial_dependence(rfc, features=[5, 6,  ], feature_names=X_test7.columns, X=X_test7, grid_resolution=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_partial_dependence(rfc, features=[ 7,8], feature_names=X_test7.columns, X=X_test7, grid_resolution=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_partial_dependence(rfc, features=[9,10], feature_names=X_test7.columns, X=X_test7, grid_resolution=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "16 print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "\n",
    "y = checker8.pop('y_target')\n",
    "X = checker8\n",
    "\n",
    "# y = cb4.pop('y_target')\n",
    "# X = cb4\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "svc = SVC(random_state=42, probability = True)\n",
    "svc.fit(X_test, y_test)\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators = 200, max_depth = 10)\n",
    "rfc.fit(X_train,y_train)\n",
    "rfc_preds = rfc.predict(X_test)\n",
    "\n",
    "\n",
    "print(classification_report(y_test,rfc_preds) ) \n",
    "print(confusion_matrix(y_test,rfc_preds)) \n",
    "\n",
    "svc_disp = plot_roc_curve(svc, X_test, y_test)\n",
    "plt.show()\n",
    "svc_preds = svc.predict(X_test)\n",
    "svc_proba = svc.predict_proba(X_test)[:,1]\n",
    "\n",
    "predsx , preds2x = svc_proba  >= .5 , svc_proba  >= .4\n",
    "\n",
    "print(classification_report(y_test,svc_preds) )\n",
    "print(confusion_matrix(y_test,svc_preds)) \n",
    "svc_disp = plot_roc_curve(svc, X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.fit(X_train, y_train)\n",
    "ax = plt.gca()\n",
    "ax.set_title('ROC Curve')\n",
    "rfc_disp = plot_roc_curve(rfc, X_test, y_test, ax=ax, alpha=0.8)\n",
    "svc_disp.plot(ax=ax, alpha=0.8)\n",
    "logmodel_disp.plot(ax=ax, alpha=0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trained_sum_of1 = [1 for x in y_train.values if x==1]\n",
    "print(sum(y_trained_sum_of1), len(y_train.values))\n",
    "y_test_sum_of1 = [1 for x in y_test.values if x==1]\n",
    "print(sum(y_test_sum_of1),'y_test', len(y_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try and recombine data frame to examine outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checker8.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "188543.2 - 117688\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checker7.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "20552/102000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "14711*20  * .2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm_to_inch(value):\n",
    "    return value/2.54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = X_test.columns \n",
    "importances = rfc.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "Random_Forest = 'Random Forest'\n",
    "plt.bar(range(X_test.shape[1]), importances[indices], color=\"b\")\n",
    "plt.title(\"{} Feature Importances\".format(Random_Forest))\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Feature importance\")\n",
    "plt.xticks(range(X_test.shape[1]), col_names[indices], rotation=45, fontsize=12, ha='right')\n",
    "plt.xlim([-1, X_test.shape[1]])\n",
    "plt.figure(figsize=(cm_to_inch(15),cm_to_inch(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(importances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = checker9.pop('y_target')\n",
    "x = checker9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train9, X_test9, y_train9, y_test9 = train_test_split(x, y, test_size=0.2, random_state=101) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dmatrix = xgb.DMatrix(data=X_train9,label=y_train9) \n",
    "test_dmatrix = xgb.DMatrix(data=X_test9,label=y_test9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"objective\":'binary:logistic','colsample_bytree': 0.6,'learning_rate': 0.1,\n",
    "       \"min_child_weight\": 5 ,'max_depth': 6, 'alpha': 10, 'eval_metric':'auc', 'subsample':0.8} \n",
    "\n",
    "cv_results = xgb.cv(dtrain=train_dmatrix, params=params, nfold=5,\n",
    "                    num_boost_round=50,early_stopping_rounds=100, metrics='auc', as_pandas=True, seed=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evallist = [(test_dmatrix, 'eval'), (train_dmatrix, 'train')] ,evallist,early_stopping_rounds=50\n",
    "xgb_one = xgb.train(params,train_dmatrix )\n",
    "# AssertionError: Must have at least 1 validation dataset for early stopping. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = xgb_one.predict(test_dmatrix, ntree_limit =xgb_one.best_ntree_limit )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_print = xgb_one.fit(test_dmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(xgb_one)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from pdpbox import pdp\n",
    " #,'interaction_regreister_delta', \n",
    "#            'delta_first_start', 'delta_reg_end',\n",
    "#            'Camp_Length', \n",
    "my_model = XGBRegressor()\n",
    "my_model.fit(X_train9, y_train9)\n",
    "feature = ['delta_first_reg','Second', 'Third']\n",
    "p = pdp.pdp_isolate(my_model, X_train9, X_train9.columns, feature)\n",
    "pdp.pdp_plot(p, feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ypred)\n",
    "#print(confusion_matrix(y_test9,ypred  ))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg1 = XGBClassifier(objective ='binary:logistic', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 6, alpha = 8, n_estimators = 12, eval_metric = 'auc', label_encoder=False)\n",
    "xg_reg1.fit(X_train9,y_train9) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg1_predict = xg_reg1.predict(X_test9) \n",
    "xg_reg1_proba = xg_reg1.predict_proba(X_test9)[:,1]\n",
    "\n",
    "preds_xg1_thresh1, preds2_xg1_thresh2 = xg_reg1_proba >=0.65 , xg_reg1_proba >=0.4\n",
    "\n",
    "xg_reg1_disp = plot_roc_curve(xg_reg1 , X_test9, y_test9)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "rfc.fit(X_train, y_train)\n",
    "ax = plt.gca()\n",
    "ax.set_title('ROC Curve')\n",
    "rfc_disp = plot_roc_curve(rfc, X_test, y_test, ax=ax, alpha=0.8)\n",
    "xg_reg1_disp2 = plot_roc_curve(xg_reg1, X_test9, y_test9, ax=ax, alpha=0.8) \n",
    "svc_disp.plot(ax=ax, alpha=0.8)\n",
    "logmodel_disp.plot(ax=ax, alpha=0.8)\n",
    "\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test9,preds_xg1_thresh1 ) )\n",
    "print(classification_report(y_test9,preds2_xg1_thresh2 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test9,preds_xg1_thresh1))  \n",
    "print(confusion_matrix(y_test9,preds2_xg1_thresh2))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[6166 1409]\n",
    " [ 872 2092]]\n",
    "\n",
    "[[6956  619]\n",
    " [1372 1592]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pint45 = 1409+2092\n",
    "pint35 = 619+1592 \n",
    "print(pint45,pint35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in ok:\n",
    "    for ii in i :\n",
    "        print(f'this is a thing from i -> {ii} being printed')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok=[[6633,  942],\n",
    " [1326, 1638]]\n",
    "\n",
    "labels = ['Did Attend', 'Did NOT Attend'] # model Names\n",
    "bottoms = [942,1326] # bottom part of column\n",
    "tops = [ 1638 ,6633 ] # Top part of column\n",
    "\n",
    "# men_std = [2, 3, 4, 1, 2] # currently not plotting std\n",
    "# women_std = [3, 5, 2, 3, 3] # currently no plotting std\n",
    "\n",
    "width = 0.35       # the width of the bars: can also be len(x) sequence\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.barh(labels,bottoms, width, label='Incorrectly predicted')\n",
    "ax.barh(labels, tops, width, bottom=bottoms,\n",
    "       label='Correctly predicted')\n",
    "\n",
    "ax.set_ylabel('Counts')\n",
    "ax.set_title('Analysis of Model Test Results ')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thought for above - should I plot 4 columns - one for each model -  showing the FP and FN split ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok=[[6633,  942],\n",
    " [1326, 1638]]\n",
    "\n",
    "labels = ['Did Attend', 'Did NOT Attend'] # model Names\n",
    "bottoms = [1326,942] # bottom part of column\n",
    "tops = [ 6633,1638 ] # Top part of column\n",
    "\n",
    "width = 0.15       # the width of the bars: can also be len(x) sequence\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "ax.bar(labels, bottoms,width,label='Incorrectly predicted')\n",
    "ax.bar(labels, tops, width, label='Correctly predicted',bottom=tops,)\n",
    "\n",
    "ax.set_ylabel('Counts')\n",
    "ax.set_title('Analysis of Model Test Results ')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg1 = XGBClassifier(objective ='binary:logistic', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 6, alpha = 8, n_estimators = 12, eval_metric = 'auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree1_predict = xg_reg1.predict(X_test) \n",
    "tree1_proba = xg_reg1.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "col_names = X_test.columns \n",
    "importances = xg_reg1.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "title = 'XG Boost Classifier'\n",
    "plt.bar(range(X_test.shape[1]), importances[indices], color=\"b\")\n",
    "plt.title(\"{} Feature Importances\".format(title))\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Feature importance\")\n",
    "plt.xticks(range(X_test.shape[1]), col_names[indices], rotation=45, fontsize=12, ha='right')\n",
    "plt.xlim([-1, X_test.shape[1]])\n",
    "plt.figure(figsize=(cm_to_inch(15),cm_to_inch(10)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg1_disp = plot_roc_curve(xg_reg1, X_test, y_test)\n",
    "rfc = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "rfc.fit(X_train, y_train)\n",
    "ax = plt.gca()\n",
    "rfc_disp = plot_roc_curve(rfc, X_test, y_test, ax=ax, alpha=0.8)\n",
    "svc_disp.plot(ax=ax, alpha=0.8)\n",
    "logmodel_disp.plot(ax=ax, alpha=0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"objective\":'binary:logistic','colsample_bytree': 0.6,'learning_rate': 0.1,\n",
    "       \"min_child_weight\": 5 ,'max_depth': 6, 'alpha': 10, 'eval_metric':'auc', 'subsample':0.8} \n",
    "\n",
    "cv_results = xgb.cv(dtrain=data_dmatrix, params=params, nfold=5,\n",
    "                    num_boost_round=50,early_stopping_rounds=100, metrics='auc', as_pandas=True, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgb.XGBClassifier()\n",
    "xgb_clf = xgb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uh = xgb_clf.predict(X_test) \n",
    "pred_proba = xgb_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = pred_proba[:,1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = X_test.columns \n",
    "importances = xgb_clf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "Random_Forest = 'XG Boost Classifier for xgb_clf'\n",
    "plt.bar(range(X_test.shape[1]), importances[indices], color=\"b\")\n",
    "plt.title(\"{} Feature Importances\".format(Random_Forest))\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Feature importance\")\n",
    "plt.xticks(range(X_test.shape[1]), col_names[indices], rotation=45, fontsize=12, ha='right')\n",
    "plt.xlim([-1, X_test.shape[1]])\n",
    "plt.figure(figsize=(cm_to_inch(25),cm_to_inch(20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotdf = pd.DataFrame({\"P1\":uh ,\"P2\":probs})\n",
    "# # ax = plotdf.plot.bar(color=[\"SkyBlue\", \"IndianRed\"], rot=0, title= \"COmpare Results\")\n",
    "# # plt.show()\n",
    "\n",
    "# df = plotdf.copy()\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.copy()\n",
    "for i in to_transfer:\n",
    "    df1[i] = X_test[i]\n",
    "print(df1.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # https://stackoverflow.com/questions/57730192/how-to-save-gridsearchcv-xgboost-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = XGBClassifier(objective ='binary:logistic', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 8, n_estimators = 10, eval_metric = 'auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg.fit(X_train,y_train)\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xg_reg.predict_proba(X_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"objective\":'binary:logistic','colsample_bytree': 0.6,'learning_rate': 0.1,\n",
    "       \"min_child_weight\": 5 ,'max_depth': 6, 'alpha': 10, 'eval_metric':'auc', 'subsample':0.8} \n",
    "\n",
    "cv_results = xgb.cv(dtrain=data_dmatrix, params=params, nfold=3,\n",
    "                    num_boost_round=50,early_stopping_rounds=100, metrics='auc', as_pandas=True, seed=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results[45:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.train(params=params, dtrain=data_dmatrix, num_boost_round=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 200 \n",
    "# xgb.plot_tree(xg_reg,num_trees=0) # plt.rcParams['figure.figsize'] = [50, 10] # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb.plot_importance(xg_reg )\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(checker3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = X_test.columns \n",
    "importances = xg_reg.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "Random_Forest = 'XG Boost Classifier for xg_reg'\n",
    "plt.bar(range(X_test.shape[1]), importances[indices], color=\"b\")\n",
    "plt.title(\"{} Feature Importances\".format(Random_Forest))\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Feature importance\")\n",
    "plt.xticks(range(X_test.shape[1]), col_names[indices], rotation=45, fontsize=12, ha='right')\n",
    "plt.xlim([-1, X_test.shape[1]])\n",
    "plt.figure(figsize=(cm_to_inch(15),cm_to_inch(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.genfromtxt('/home/allen/Galva/capstones/capstone2/src/explore/train_4_model.csv',delimiter=',' ,skip_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = [x for x in range(dataset.shape[1]) if x !=5]\n",
    "selector2 = [x for x in range(dataset.shape[1]) if x ==5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset[:,selector]\n",
    "y2 = dataset[:,selector2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.delete(dataset,6,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1,input_dim = 46, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy',optimizer = 'rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tensorflow.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try: \n",
    "        for gpu in gpus:\n",
    "            tensorflow.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e, 'BTW ***********************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=y,y=y2, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y2[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = model.predict(y)\n",
    "print(predictions2[:10].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
